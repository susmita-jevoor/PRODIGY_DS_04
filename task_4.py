# -*- coding: utf-8 -*-
"""TASK_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VrLjQieCSeCU22S16i-Coe4oADCKSNf0

**PRODIGY INFOTECH INTERNSHIP**

**TASK 4**:Analyze and visualize sentiment patterns in social media data to understand public opinion and attitudes towards specific topics or brands.

**DONE BY**: SUSMITA JEVOOR
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""**IMPORTING AMAZON REVIEW DATASET**"""

df=pd.read_csv('Amazon_Review.csv')
df

df.info()

df.tail(10)

"""Dropping the rows having a particular value as NaN"""

df.dropna(inplace=True)

df.info()

df.describe(include='all')

"""**SENTIMENT ANALYSIS**"""

#Analysing the review sentiments from the datasets
data_sentiment_count=df['Own_Rating'].value_counts()
print(data_sentiment_count)

sns.countplot(x='Own_Rating',data=df,palette=['green','yellow','red'])
plt.title('Sentiment Distribution before analysis')
plt.xlabel('Sentiments')
plt.show()

#Sentimental analysis using TextBlob and classify sentiments
from textblob import TextBlob

#Take the dataset in different variable
data1=df
def get_sentiment(text):
  analysis=TextBlob(text)
  if analysis.sentiment.polarity>0:
    return 'Positive'
  elif analysis.sentiment.polarity==0:
    return 'neutral'
  else:
    return 'Negative'

#Creating anew column sentiment to store the sentiments
data1['Sentiment']=data1['Review_text'].apply(get_sentiment)

#Count the sentiments
sentiment_counts=data1['Sentiment'].value_counts()
print(sentiment_counts)

#PLotting the sentiment distribution
sns.countplot(x='Sentiment',data=data1,palette=['green','yellow','red'])
plt.title('Sentiment Distribution after analysis')
plt.xlabel('Sentiment')
plt.show()

#Sentiment analysis using NLTX Vader and classify sentiments based on their product category
import nltk
nltk.download('vader_lexicon')
from nltk.sentiment.vader import SentimentIntensityAnalyzer

#take the dataset on different variable
data2=df

sid=SentimentIntensityAnalyzer()
data2['Sentiment Score']=data2['Review_text'].apply(lambda text: sid.polarity_scores(text)['compound'])

#Map sentiment scores to categories
def get_sentiment_category(score):
  if score>=0.05:
    return 'Positive'
  elif score<=-0.05:
    return 'Negative'
  else:
    return 'Neutral'

data2['Sentiment Category']=data2['Sentiment Score'].apply(get_sentiment_category)

#Count the sentiments
sentiment_counts=data2['Sentiment Category'].value_counts()
print(sentiment_counts)
print()

sentiment_by_category=pd.crosstab(index=data2['Category'],columns=data2['Sentiment Category'])
print(sentiment_by_category)
print()

#Visualize sentiment distribution across categories
plt.figure(figsize=(10,6))
sns.countplot(x='Category',hue='Sentiment Category',data=data2,palette=['green','blue','red'])
plt.title('Sentiment Distribution across platforms')
plt.xlabel('Category')
plt.ylabel('Count')
plt.xticks(rotation=30)
plt.legend(title='Sentiment')
plt.show()

"""**WORD CLOUD**"""

#create word clouds based on the sentiments using the data2 dataset

from wordcloud import WordCloud

#Converting 'review' columnto strings
df['Review_Header']=df['Review_Header'].astype(str)

positive_reviews=''.join(data2[data2['Sentiment Category']=='Positive']['Review_Header'])
negative_reviews=''.join(data2[data2['Sentiment Category']=='Negative']['Review_Header'])
neutral_reviews=''.join(data2[data2['Sentiment Category']=='Neutral']['Review_Header'])

plt.figure(figsize=(10,8))
wordcloud_positive=WordCloud(width=800,height=400,background_color='white').generate(positive_reviews)
plt.imshow(wordcloud_positive,interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for Positive Reviews')
plt.show()

plt.figure(figsize=(10,8))
wordcloud_neutral=WordCloud(width=800,height=400,background_color='white').generate(neutral_reviews)
plt.imshow(wordcloud_neutral,interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for Neutral Reviews')
plt.show()

plt.figure(figsize=(10,8))
wordcloud_negative=WordCloud(width=800,height=400,background_color='white').generate(negative_reviews)
plt.imshow(wordcloud_negative,interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for Negative Reviews')
plt.show()

"""**INFERENCE**: The Word Cloud gives us a gist of trending keywords according to the respective sentiment

ADDITIONAL ANALYSIS
"""

from sklearn.feature_extraction.text import CountVectorizer

vectorizer=CountVectorizer(stop_words='english',max_features=10)
word_frequency=vectorizer.fit_transform(data2['Review_Header'])
words=vectorizer.get_feature_names_out()
word_counts=word_frequency.sum(axis=0).A1

plt.figure(figsize=(8,6))
sns.barplot(x=word_counts,y=words,palette='inferno')
plt.title('Top 10 Frequent Words in  Reviews')
plt.xlabel('Word Count')
plt.ylabel('Words')
plt.show()

top_ratings=df['Rating'].value_counts()

plt.figure(figsize=(10,6))
sns.barplot(x=top_ratings.index,y=top_ratings.values,palette='magma')
plt.title('Most frequent ratings in  Reviews')
plt.xlabel('Rating')
plt.ylabel('Frequency')
plt.show()

from collections import Counter
# get the most common words in positive sentiments
positive_df=data2[data2['Sentiment Category']=='Positive']

top_positive=Counter([word for sentence in positive_df['Review_text'] for word in sentence.split()
])
top_positive=pd.DataFrame(top_positive.most_common(20))
top_positive=top_positive.iloc[1:,:]
top_positive.columns=['Common_words','count']

top_positive.style.background_gradient(cmap='Greens')

# get the most common words in negative sentiments
negative_df=data2[data2['Sentiment Category']=='Negative']

top_negative=Counter([word for sentence in negative_df['Review_text'] for word in sentence.split()
])
top_negative=pd.DataFrame(top_negative.most_common(20))
top_negative=top_negative.iloc[1:,:]
top_negative.columns=['Common_words','count']

top_negative.style.background_gradient(cmap='Reds')

# get the most common words in neutral sentiments
neutral_df=data2[data2['Sentiment Category']=='Neutral']

top_neutral=Counter([word for sentence in negative_df['Review_text'] for word in sentence.split()
])
top_neutral=pd.DataFrame(top_neutral.most_common(20))
top_neutral=top_neutral.iloc[1:,:]
top_neutral.columns=['Common_words','count']

top_neutral.style.background_gradient(cmap='Blues')